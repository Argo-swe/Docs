\section{Riunione}
\subsection{Ordine del giorno}
\begin{itemize}
	\item Presentazione di una demo del software;
	\item Confronto sul cambio di tecnologie;
	\item Range valori delle \glossario{metriche di prodotto}.
\end{itemize}

\subsection{Argomenti e temi dell'incontro}

\subsubsection{Dimostrazione di una demo del software}

\par \textbf{Descrizione:} I programmatori hanno mostrato a schermo una demo al fine di capire se le funzionalità fino ad ora sviluppate fossero state comprese nella loro interezza e, di conseguenza, fossero state sviluppate correttamente.Le funzionalità che sono state provate e mostrate inizialmente sono state: 
\begin{itemize}
	\item La possibilità di mostrare all'utente il \glossario{dizionario dati} in linguaggio naturale in modo tale che sia più comprensibile all’utente che interrogazioni può fare;
	\item L’inserimento di nuovi dizionari dati.
	
\end{itemize}

\par \textbf{Risposta:} E’ stato data l’approvazione per la strutturazione generale delle funzionalità .

\par \textbf{Descrizione:} Sono state mostrate le funzionalità di generazione di un \glossario{prompt} successivo alla scelta di un \glossario{dizionario dati} e l’inserimento di una richiesta in linguaggio naturale il tutto in lingua inglese dato che il modello utilizzato fino ad ora utilizza questa lingua.

\par \textbf{Risposta:} La Proponente ha consigliato di utilizzare Bertino come \glossario{modello} in lingua italiana.

\par \textbf{Descrizione:} Il gruppo ha già lavorato con Bertino in precedenza ma i risultati degli score per la scelta delle tabelle per il \glossario{prompt} erano di molto superiori rispetto ad altri modelli e quindi sembrava che Bertino semplificasse di molto la scelta e i risultati sembravano essere troppo uniformati.
\par \textbf{Risposta:} La proponente ha quindi consigliato di usare Marco-BERTino dato che il capitolato esplicitava l’interesse per la lingua italiana. Viene spiegato che è importante avere la descrizione in italiano per non far ricadere la formulazione della query da parte degli \glossario{LLM} sulla descrizione delle tabelle restituite ovvero il loro lato semantico a causa di tutto il training che i modelli hanno attuato su frasi SQL in inglese.

\par \textbf{Descrizione:} E’ stata testata una frase per la generazione del \glossario{prompt}.
\par \textbf{Risposta:} La proponente ha approvato la funzionalità cardine e ha proposto dei test da fare che sono stati provati durante il colloquio e da riprodurre in seguito. Inizialmente è stato proposto di usare il \glossario{prompt} generato dall’applicativo su chat.lmsys.org per testare le \glossario{query} con diversi modelli e non solo con ChatGpt per vedere se il \glossario{prompt} fosse abbastanza chiaro anche per modelli LLM più piccoli.
\par \textbf{Descrizione:} Il \glossario{prompt} generato è stato testato con 7 modelli di LLM diversi (chatGpt, yi-1.5-34b, qwen2-72b, claude-3-haiku, command-r, llama-3-8b, openhermes-mistral). I risultati emersi hanno confermato la correttezza del \glossario{prompt} generato in quanto tutti i modelli hanno restituito la stessa \glossario{query} in SQL se non per l'inserimento della maiuscola per i nomi propri che alcuni modelli hanno dato come precondizione anche se non era specificato nella frase inserita dall’utente né dal \glossario{prompt} generato.

\par \textbf{Risposta:} Visti i buoni risultati la Proponente chiede di cambiare anche il DBMS e non usare solo MariaDB ma anche Postgres.

\par \textbf{Descrizione:} Dato il test di questa funzionalità si approfondisce il fatto che potrebbe essere una funzionalità aggiuntiva da implementare e da applicare come caso d’uso come la selezione della lingua in cui inserire la richiesta in linguaggio naturale.

\par \textbf{Risposta:} La Proponente risulta interessata a questa feature e ne appoggia l’implementazione.
\par \textbf{Descrizione:} Si testano altre \glossario{query} e si analizza la struttura del \glossario{prompt}.

\par \textbf{Risposta:} La proponente evidenzia una problematica in quanto nel \glossario{prompt} restituito fino ad ora vengono riportati solo i nomi delle tabelle e non le descrizioni ma in un caso realistico i nomi delle colonne nel \glossario{database} non sono significativi e necessitano di una descrizione.Il \glossario{prompt} restituito è quindi da modificare e ampliare. 
\par \textbf{Descrizione:} Alla luce della nuova struttura del \glossario{prompt} da restituire viene chiesto se sia possibile ottimizzare restituendo solo le descrizione dei nomi di colonne non significativi e risparmiare quelli parlanti da se’.
\par \textbf{Risposta:} La Proponente rassicura che quest’ultima sarebbe una ottimizzazione non significativa in quanto per esempio ChatGpt gestisce 128K di richiesta e Gemini 1Mln quindi si possono restituire senza discriminante le descrizioni di tutte le tabelle. Sarebbe inoltre difficile decidere con quale criterio selezionare quali colonne descrivere e quali no.

\par \textbf{Descrizione:} Si passa a testare delle richieste in linguaggio naturale più articolate e meno specifiche.

\par \textbf{Risposta:}  La Proponente mette in luce che sul \glossario{prompt} è stata data più importanza a trovare la soluzione rispetto alla più precisa, è stata privilegiata la recall rispetto alla precisione. E’ stata una scelta però necessaria che la Proponente si aspettava in quanto il problema si sarebbe presentato se avessimo scambiato l’ordine di queste due caratteristiche. 

\par \textbf{Descrizione:} Viene mostrata la funzionalità di \glossario{debugging} che è sviluppata su frasi di test di cui viene tratto il punteggio che hanno preso le tabelle e le colonne di quest’ultime per spiegare perché sono state selezionate certe parti di \glossario{database} rispetto ad altre. Il debugger restituisce dei punteggi ,score, per risalire al meccanismo di selezione del \glossario{prompt}. 
\par \textbf{Risposta:} Ciò che qui viene restituito è quello che si aspetta la Proponente di trovare anche nella generazione del \glossario{prompt} ovvero le descrizioni di tabelle e colonne per il resto la funzionalità risulta essere corretta. 


\subsection{Cambio di Tecnologie}


\par \textbf{Descrizione:} Terminata la dimostrazione della demo il gruppo ha condiviso di aver deciso di cambiare le tecnologie.
\par \textbf{Risposta:} La Proponente ha accolto l'informazione ribadendo che rimane indifferente alle scelte tecnologiche ma che la scelta sembra essere stata maturata dopo una valutazione profonda anche delle problematiche che si sarebbero potute presentare in futuro come era stato consigliato da quest’ultima negli incontri precedenti.

\subsection{Range valori delle metriche di prodotto}

\par \textbf{Descrizione:}Il gruppo ha voluto capire se, nei mesi precedenti durante l’affiancamento dei lavori dei gruppi che hanno preceduto Argo nello sviluppo di Chat SQL, le conclusioni a cui si è arrivati siano state abbastanza precise per capire come si potrebbero valutare le \glossario{metriche di qualità} e che range selezionare per valutare il prodotto.
\par \textbf{Risposta:} La Proponente evidenza come gli LLM evolvono a velocità esponenziali e ciò che mesi fa sembrava essere molto difficile ora probabilmente è già stato fatto. Settare dei range per la qualità del prodotto su questo capitolato ora sembra essere più semplice di prima in quanto è emerso come sia più semplice, e quindi fattibile, del previsto generare codice SQL corretto dato un \glossario{prompt} di partenza.La Proponente invita quindi il gruppo,date queste premesse, a provare \glossario{query} più complesse anche con subqueries nei mesi successivi per vedere se si possono raggiungere comunque buoni risultati come con quelle testate fino ad ora.

\par \textbf{Descrizione:} Vengono illustrati i test che si stanno implementando per la verifica del prodotto. La Proponente illustra un possibile test che può essere implementato in futuro e si testa una prima volta durante il colloquio. 
\par \textbf{Risposta:} La Proponente chiede di prendere la frase in linguaggio naturale inserita dell'utente e farsela riscrivere da ChatGpt in modo differente e poi confrontare il prompt generato e la frase SQL che ne deriva.Se quest’ ultime coincidono è un buon parametro di valutazione.La Proponente consiglia di ripetere il test conun modello in locale con 5 frasi diverse generate da una comune da un LLM.
